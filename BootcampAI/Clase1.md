
# D铆a 4  
## Bootcamp Inteligencia Artificial - Integrador  

---

## 5. Funci贸n de Activaci贸n

Una funci贸n de activaci贸n es una funci贸n matem谩tica utilizada en una neurona artificial para introducir **no linealidad** en el modelo. Esto permite que la red neuronal pueda aprender y representar funciones complejas.  

Ejemplos comunes de funciones de activaci贸n incluyen:

- Funci贸n sigmoide  
- Tangente hiperb贸lica (tanh)  
- Unidad lineal rectificada (ReLU)  

---

## 6. Entrenamiento de una Red Neuronal

El entrenamiento de una red neuronal es el proceso de ajustar los **pesos (weights)** y **biases** de la red mediante un algoritmo de optimizaci贸n, generalmente basado en el **descenso de gradiente**.  

El objetivo es minimizar la **funci贸n de p茅rdida**, que mide la diferencia entre las predicciones de la red y los valores reales.  

Durante el entrenamiento, la red aprende a **generalizar patrones** a partir de los datos de entrenamiento para hacer predicciones en datos nuevos.

---

## 7. Backpropagation (Retropropagaci贸n)

Backpropagation es un algoritmo utilizado para entrenar redes neuronales multicapa.  

Calcula el **gradiente** de la funci贸n de p茅rdida con respecto a los pesos de la red, utilizando la **regla de la cadena**. Este gradiente se utiliza luego para actualizar los pesos de manera que se minimice la p茅rdida.  

Es esencial para la eficiencia del entrenamiento de redes neuronales profundas.

### 驴Qu茅 es el gradiente?

El gradiente es un concepto derivado de la optimizaci贸n. Representa la direcci贸n en la cual debe moverse una funci贸n para reducir el error hasta acercarlo a 0.  

Con esta direcci贸n podemos saber c贸mo modificar los pesos de la red neuronal para minimizar la funci贸n de p茅rdida.

---

## 8. Overfitting (Sobreajuste)

Es un fen贸meno en el que una red neuronal se entrena tan bien con los datos de entrenamiento que pierde la capacidad de generalizar a datos nuevos.  

Esto ocurre cuando el modelo es muy complejo y comienza a **memorizar los datos** en lugar de aprender patrones.

### 驴C贸mo prevenir el sobreajuste?

Algunas t茅cnicas comunes son:

- Dropout  
- Uso de un conjunto de validaci贸n  

Generalmente se sospecha overfitting cuando la precisi贸n en entrenamiento se acerca demasiado al 100%.

Cada 谩rea espec铆fica tiene un margen de error aceptado seg煤n el tipo de problema. Siempre ha habido un especialista que eval煤a si el modelo es adecuado o no dependiendo del contexto y las m茅tricas utilizadas. En algunos casos, este proceso puede relacionarse con enfoques como el aprendizaje por refuerzo.

---

## Funci贸n de Costo o P茅rdida

La funci贸n de costo o p茅rdida es una funci贸n matem谩tica que cuantifica la diferencia entre las predicciones de la red y los valores reales en los datos de entrenamiento.

---

## Caso Interesante: Entrenamiento Prolongado y Generalizaci贸n Emergente

Un investigador de OpenAI olvid贸 detener una sesi贸n de entrenamiento antes de irse de vacaciones.

Para cuando regres贸, el modelo ya hab铆a asimilado la informaci贸n. Pas贸 de la **memorizaci贸n pura** a la **comprensi贸n genuina**, una transici贸n que aparece repentinamente tras largos per铆odos de entrenamiento.

Welch Labs detalla exactamente lo que sucedi贸:

- El modelo memoriza los datos de entrenamiento de forma temprana.  
- La p茅rdida de entrenamiento se reduce a cero, mientras que la precisi贸n en prueba se mantiene baja.  
- El entrenamiento contin煤a sin progreso visible.  
- De repente, la precisi贸n en prueba se vuelve casi perfecta.  

No hubo datos nuevos.  
No hubo cambios en la arquitectura.  
Solo m谩s entrenamiento, con la disminuci贸n del peso (*weight decay*) impulsando lentamente al modelo hacia una soluci贸n m谩s simple y general.

### Idea Clave

Parte del aprendizaje m谩s importante puede ocurrir mucho despu茅s de que la p茅rdida de entrenamiento se haya estabilizado.

Esto desaf铆a la idea tradicional de que entrenar despu茅s del sobreajuste es simplemente computaci贸n desperdiciada.

---

## Modelos de Caja Negra, Caja Blanca y Caja Gris

###  Caja Negra (Black Box)

Un modelo de **caja negra** es aquel en el que no se entiende f谩cilmente c贸mo se llega a una decisi贸n interna.  

Solo se observan:

- **Entradas (inputs)**
- **Salidas (outputs)**

Pero el proceso interno que transforma la entrada en salida no es interpretable o no es accesible para el usuario.

Este tipo de modelos es com煤n en:

- Inteligencia Artificial (especialmente redes neuronales profundas)
- Machine Learning avanzado
- Ciberseguridad

### Ejemplo

Cuando utilizas un GPS, ingresas un destino y el sistema te muestra una ruta con varios puntos. Sin embargo, no sabes exactamente qu茅 c谩lculos internos realiza para determinar esa ruta.

Otro ejemplo es un usuario com煤n usando ChatGPT:  
Escribe una pregunta y recibe una respuesta, pero no puede ver ni entender el proceso interno del modelo.

---

###  Caja Blanca (White Box)

Un modelo de **caja blanca** es aquel en el que el funcionamiento interno es completamente visible y entendible.

Se puede:

- Analizar c贸mo se toman las decisiones
- Revisar reglas y c谩lculos
- Interpretar cada paso del proceso

Ejemplos comunes:

- Regresi贸n lineal
- rboles de decisi贸n simples
- Algoritmos basados en reglas

Estos modelos son altamente interpretables y se usan mucho cuando la transparencia es importante (por ejemplo, en medicina o finanzas).

---

###  Caja Gris (Gray Box)

Un modelo de **caja gris** es un punto intermedio entre caja negra y caja blanca.

Se tiene conocimiento parcial del funcionamiento interno:

- Se entienden algunas partes del modelo.
- O se pueden aplicar t茅cnicas de interpretabilidad para analizarlo.

Ejemplos:

- Redes neuronales con t茅cnicas de interpretaci贸n (SHAP, LIME).
- Sistemas donde se conoce la arquitectura general, pero no cada detalle interno.

---

## Importancia en IA y Ciberseguridad

En inteligencia artificial y ciberseguridad, entender si un sistema es caja negra, blanca o gris es clave para:

- Evaluar riesgos
- Detectar sesgos
- Garantizar transparencia
- Cumplir regulaciones

La tendencia actual en IA es desarrollar modelos cada vez m谩s potentes, pero tambi茅n m谩s interpretables.
